---
title: "02_Bootstrapping"
author: "Simone Zaghen"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    toc: true
    number_section: true
    toc_float: 
      collapsed: false
      smooth_scroll: true
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../results/") })
---

The idea is to assign time and cell cycle to cells and then look at the variance of the genes in the same cell cycle/timeframe window. To do this without losing statistical power/accuracy, we need to check how many cells we need in each timeframe/cycle phase. To do this, we bootstrap the dataset and check which residuals we have with a specific number of cells, to see whenever we get close to the residuals previously calculated. This will tell us how big the subset of cells needs to be not to lose statistical significance. 

# Load packages

```{r, results='hide', message=FALSE}
library(conflicted)
library(tidyverse)
library(ggridges)

source("functions/loadNoRapaTreat.R")
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")

#create folders
if (!dir.exists("../results/Bootstrapping")){
  dir.create("../results/Bootstrapping/")}

```

# Load data

Load the gene count matrix and  the metadata in which Chris estimated the cell cycle phase and assigned a pseudotime to the cells. The loadNoRapaTreat takes care of importing those two dataframes, merging them, only keeping the wt strain before rapa treatment, assigning timebins to cell, and normalizing the gene counts. Check the function itself for more info.

```{r}
df <- loadNoRapaTreat(rawdata_path = "../data/2021_RAPA_TIMECOURSE.tsv.gz",
                      metadata_path = "../data/Cell_Cycle_Metadata_01112024.tsv.gz")

df_stats <- read.csv2("../results/Gene_Variance/gene_stats_and_description.csv", 
                      row.names = 1)
```

# Bootstrap

Perform bootstrap and save the regression lines and the residuals of each iteration

```{r}
reg_lines <- data.frame() #create df to store regression lines
residuals <- data.frame() #create df to store residuals

sample_size = c(250, 500, 750, 1000, 1500, 2000) #how many cells to sample

nperm <- 1000 #set how many times to re-sample

for (j in 1:length(sample_size)) { #iterates for all the sample sizes i want
  for (i in 1:nperm) { #repeats the sampling X times
    sub_df <- df[sample(nrow(df), sample_size[j]),] #subset/sample the df
    
    #calculate stats
    mean = apply(sub_df[1:5843], 2, mean, na.rm = T) #average exp of each gene
    sd = apply(sub_df[1:5843], 2, sd) #average sd of each gene
    CV = sd/mean #calculate coefficient of variation
    stats <- rbind(mean, CV) #merge stats in one df
    stats <- as.data.frame(t(stats)) #transpose
    stats <- filter(stats, mean > 0.01) #remove genes with low mean

    #model
    model <- lm(log10(CV) ~ log10(mean), data = stats)
    
    #save intercept and slope into df
    coef <- data.frame(t(coef(model)))
    coef$sample_size <- sample_size[j]
    reg_lines <- rbind(reg_lines, coef)
    
    #save residuals in df
    tmp_residuals <- data.frame(genes = names(model$residuals), 
                                residuals = model$residuals,
                                sample_size = sample_size[j],
                                row.names = NULL)
    residuals <- rbind(residuals, tmp_residuals)
    }
}

rm(list = c("coef", "model", "stats", "sub_df", "CV",
            "i", "j", "mean", "nperm", "sample_size",
            "sd", "tmp_residuals")) #clean workspace

```

Append data from original model 

```{r}
#Append results from model with all cells
reg_lines <- rbind(reg_lines, c(0.2842771, -0.4808712, 45237))
colnames(reg_lines) <- c("intercept", "slope", "sample_size")

#append residuals of model with all cells
tmp <- select(df_stats, c("genes", "residuals")) %>%
  mutate(sample_size = 45237)
residuals <- rbind(residuals, tmp)

write.csv2(reg_lines,
           "../results/Bootstrapping/regression_lines.csv")
write.csv2(residuals,
           "../results/Bootstrapping/residuals.csv")

rm("tmp")

```

# Plot regression lines

```{r}
ggplot() +
  geom_point(data = df_stats,
             aes(x = log10(mean),
                 y = log10(CV)),
             color = "grey") +
  geom_abline(data = reg_lines,
              aes(slope = slope,
                  intercept = intercept,
                  color = as.factor(sample_size))) +
  labs(color="re-sampling size")

ggplot() +
  geom_point(data = df_stats,
             aes(x = log10(mean),
                 y = log10(CV)),
             color = "grey") +
  geom_abline(data = reg_lines,
              aes(slope = slope,
                  intercept = intercept,
                  color = as.factor(sample_size))) +
  labs(color="re-sampling size") +
  theme(legend.position = "none") +
  facet_wrap(~sample_size, ncol = 2)

```

Plot distribution of slopes and intercepts

```{r, fig.show='hold'}
reg_lines %>%
  filter(sample_size != 45237) %>%
ggplot(aes(x=slope)) + 
  geom_density() +
  ggtitle("Distribution of slope values") +
  facet_wrap(~sample_size)
  
reg_lines %>%
  filter(sample_size != 45237) %>%
ggplot(aes(x = intercept)) + 
  geom_density() +
  ggtitle("Distribution of intercept values") +
  facet_wrap( ~ sample_size)


```

# Calculate Spearman's rank correlation coefficient

For each re-sampling size, calculate the average residual of each gene. Then pivot the df in the wide form since the cor function takes wide df as input.

```{r, message=F}
mean_res <- residuals %>%
  group_by(sample_size, genes) %>%
  summarize(mean = mean(residuals, na.rm = T)) %>%
  pivot_wider(names_from = sample_size, 
              values_from = mean) %>%
  drop_na() %>% #remove rows in which there are NA. 
  column_to_rownames(var = "genes") 

```

Calculate the Spearman's coefficient on this

```{r}
spearman_coeff <- cor(mean_res, method = "spearman" )
write.csv2(spearman_coeff, "../results/Bootstrapping/spearman_coeff.csv")

spearman_coeff

```

# Calculate confidence intervals

```{r}
ci_results <- residuals %>%
  group_by(genes, sample_size) %>%
  summarise(
    lower = quantile(residuals, 0.025, na.rm = TRUE),
    upper = quantile(residuals, 0.975, na.rm = TRUE),
    mean_residual = mean(residuals, na.rm = TRUE),
    .groups = "drop") %>%
  drop_na()

write.csv2(ci_results,
           "../results/Bootstrapping/confidence_interval.csv")

```

```{r}
ci_results %>%
  filter(!sample_size == "45237") %>%
  group_by(sample_size) %>%
  summarise(
    mean_ci_width = mean(upper - lower, na.rm = TRUE),
    median_ci_width = median(upper - lower, na.rm = TRUE),
    .groups = "drop") %>%
  ggplot(aes(x = sample_size, 
             y = mean_ci_width)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Confidence Interval Width vs. Sample Size",
    x = "Sample Size",
    y = "Mean CI Width") +
  theme_minimal()

```

```{r, warning=FALSE, message=FALSE}
ci_results %>%
  ggplot() +
  geom_density_ridges(
    aes(x = mean_residual, 
        y = as.factor(sample_size), 
        fill = as.factor(sample_size)),
    alpha = 0.6, 
    scale = 2, 
    ) +
  scale_x_continuous(limits = c(-0.1, 0.1))+
  labs(
    x = "Residual Values",
    y = "Sample Size",
    fill = "Sample Size"
  ) +
  theme_minimal()

```

# Count cells in each cell cycle phase and in each timepoint

Count cells in each cell cycle phase and in each timepoint. Based on this, we will decide the sizes of the resampling when bootstrapping

## Count in cell cycle phase

```{r}
ggplot(df, 
       aes(x = factor(Cell_Cycle_Phase, 
                      levels = c("G1", "S", "G2", "M", "M-G1")))) +
  geom_bar(fill = "grey") +
  labs(
    title = "Cells in Each Cell Cycle Phase",
    x = "Cell Cycle Phase",
    y = "Count"
  ) +
  theme_minimal()

```

## Count in cell cycle time

```{r}
interval_sizes <- c(1, 2, 3, 4, 5, 6)
cells_in_timebins <- list()

# Loop over the interval sizes
for (interval in interval_sizes) {
  tmp <- df %>%
    mutate(time_bin = floor(Cell_Cycle_Time / interval) * interval) %>%
    count(time_bin) %>%
    arrange(time_bin) %>%
    mutate(interval = interval)
  cells_in_timebins <- rbind(cells_in_timebins, tmp)
}

write.csv2(cells_in_timebins,
           "../results/Bootstrapping/cells_in_timebins.csv")

rm(interval_sizes, tmp)

```

Plot

```{r}
cells_in_timebins %>%
  ggplot(aes(x=time_bin,
             y=n)) + 
  geom_bar(stat = "identity") + 
  theme_bw() + 
  ggtitle("Cell count distribution based on bin size (minutes)") +
  facet_wrap(~interval,
             scales = "free_y")

```

Plot minimum bin size vs size of timebin

```{r}
cells_in_timebins %>%
  filter(time_bin >= 3 & time_bin <= 86) %>% #remove tail ends where counting is not very accurate
  group_by(interval) %>%
  summarise(min_n = min(n)) %>%
  ggplot(aes(x = interval, 
             y = min_n)) +
  geom_point(size = 3) +
  geom_line() +
  scale_x_continuous(breaks = 1:6) +
  labs(title = "Minimum Cell Counts in Each Interval", 
       x = "Interval", 
       y = "Cell Count (n)") +
  theme_minimal()

```

